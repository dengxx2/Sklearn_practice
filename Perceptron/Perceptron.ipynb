{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 感知机模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:02:49.394004Z",
     "start_time": "2020-04-26T13:02:49.388423Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始数据划分成训练集和测试集(下次直接读取对应划分好已经存储起来的数据即可)\n",
    "\n",
    "1. 打乱数据\n",
    "2. 20%留做测试集,80%作为训练集和验证集,分别存储下来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:02:49.440780Z",
     "start_time": "2020-04-26T13:02:49.397250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dfp</th>\n",
       "      <th>nean</th>\n",
       "      <th>pnian</th>\n",
       "      <th>nvc</th>\n",
       "      <th>nnm</th>\n",
       "      <th>nnmp</th>\n",
       "      <th>vcp</th>\n",
       "      <th>njf</th>\n",
       "      <th>nsf</th>\n",
       "      <th>we</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042969</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>7.442584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7.733537</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dfp  nean  pnian  nvc  nnm      nnmp  vcp  njf  nsf        we  class\n",
       "0  0.042969     1      0    5  108  0.837209  0.0    0   20  7.442584      1\n",
       "1  0.002476     1      0    5    6  0.272727  0.0    2    8  7.733537      1"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打乱数据\n",
    "df = pd.read_csv(\"output.csv\")\n",
    "total = len(df)\n",
    "print(total)\n",
    "df = shuffle(df)  \n",
    "df = df.reset_index()  # 重新建立索引\n",
    "df = df.iloc[:, 2:]  # 重新建立索引后去掉\"index\"列\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:02:49.525413Z",
     "start_time": "2020-04-26T13:02:49.442742Z"
    }
   },
   "outputs": [],
   "source": [
    "# 划分出20%作为测试集, 80%作为训练集和验证集\n",
    "\n",
    "test_data = df[:int(0.2*total)]\n",
    "total_test = len(test_data)\n",
    "test_data.to_csv( \"test_data_\" + str(total_test)+ \".csv\",header = True,index = False,sep='\\t')\n",
    "# test_data = pd.read_csv(\"test_data_800.csv\",header = 0,sep='\\t') # 读取测试数据\n",
    "\n",
    "data = df[int(0.2*total):]\n",
    "total_data = len(data)\n",
    "data.to_csv( \"data_\" + str(total_data)+ \".csv\",header = True,index = False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取训练集数据,并划分为80%的训练集,20%的验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:02:49.542565Z",
     "start_time": "2020-04-26T13:02:49.527961Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练集数据\n",
    "data = pd.read_csv(\"data_3200.csv\",header = 0,sep='\\t') # 读取训练数据\n",
    "\n",
    "# 将特征划分到 X 中，标签划分到 Y 中\n",
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:,-1]\n",
    "# 使用train_test_split函数随机划分数据集(训练集占80%，验证集占20%)\n",
    "train_X,test_X, train_y, test_y = train_test_split(x,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:02:49.554708Z",
     "start_time": "2020-04-26T13:02:49.544585Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengxx/py3env/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/dengxx/py3env/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n",
      "/home/dengxx/py3env/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['StandardScaler_model.m']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为了追求机器学习和最优化算法的最佳性能，我们将特征缩放\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_X) # 估算每个特征的平均值和标准差\n",
    "\n",
    "train_X_std = sc.transform(train_X)\n",
    "test_X_std = sc.transform(test_X)  # 这里用同样的参数来标准化测试集，使得测试集和训练集之间有可比性\n",
    "\n",
    "# 存储和加载标准化\n",
    "joblib.dump(sc, \"StandardScaler_model.m\")\n",
    "# sc = joblib.load(\"StandardScaler_model.m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T06:39:56.498748Z",
     "start_time": "2020-04-26T06:39:56.042380Z"
    }
   },
   "source": [
    "## 训练感知机模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:02:49.957229Z",
     "start_time": "2020-04-26T13:02:49.556082Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengxx/py3env/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.965625"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_iter：可以理解成梯度下降中迭代的次数\n",
    "# eta0：可以理解成梯度下降中的学习率\n",
    "# random_state：设置随机种子的，为了每次迭代都有相同的训练集顺序\n",
    "ppn = Perceptron(n_iter=4000, eta0=0.05, random_state=0)\n",
    "ppn.fit(train_X_std, train_y)\n",
    "y_pred = ppn.predict(test_X_std)\n",
    "accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-fold 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:02:51.925545Z",
     "start_time": "2020-04-26T13:02:49.958779Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengxx/py3env/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/dengxx/py3env/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/dengxx/py3env/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/dengxx/py3env/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/dengxx/py3env/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/dengxx/py3env/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉验证结果: [0.95625   0.9546875 0.9203125 0.8859375 0.9421875]\n"
     ]
    }
   ],
   "source": [
    "x = sc.transform(x)\n",
    "accs = cross_val_score(ppn, x, y, cv = 5)\n",
    "print('交叉验证结果:',accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存储和加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:02:51.931434Z",
     "start_time": "2020-04-26T13:02:51.926980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_model.m']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 感知器模型\n",
    "joblib.dump(ppn, \"train_model.m\")\n",
    "# ppn = joblib.load(\"train_model.m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集上的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:02:51.947858Z",
     "start_time": "2020-04-26T13:02:51.932759Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dengxx/py3env/lib/python3.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取测试集\n",
    "test_data = pd.read_csv(\"test_data_800.csv\",header = 0,sep='\\t') # 读取测试数据\n",
    "test_data_x = test_data.iloc[:, :-1]\n",
    "label = test_data.iloc[:,-1]\n",
    "\n",
    "# 特征标准化\n",
    "sc = joblib.load(\"StandardScaler_model.m\")\n",
    "test_data_x_std = sc.transform(test_data_x)  # 这里用同样的参数来标准化测试集，使得测试集和训练集之间有可比性\n",
    "\n",
    "# 加载模型\n",
    "ppn = joblib.load(\"train_model.m\")\n",
    "y_pred = ppn.predict(test_data_x_std)\n",
    "accuracy_score(label, y_pred)  # 计算模型在测试集上的准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
